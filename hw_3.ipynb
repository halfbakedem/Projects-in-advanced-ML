{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxGTgJz152A"
   },
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gSrVJwp3E9H"
   },
   "source": [
    "## Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain.\n",
    "\n",
    "The SST-2 (Stanford Sentiment Treebank 2) competition dataset is a popular benchmark dataset for sentiment analysis, containing a large number of movie reviews labeled with their corresponding sentiment (positive or negative). The dataset consists of approximately 62,000 movie reviews, where each review is represented as a parse tree with each node in the tree labeled with a sentiment label. The reviews are split into training and testing sets, with 5,000 reviews in the testing set.\n",
    "\n",
    "Building a predictive model using the SST-2 dataset can be practically useful in a number of ways. One of the most straightforward applications is to use such a model to automatically classify the sentiment of new movie reviews, allowing businesses to monitor customer feedback and sentiment in near-real-time. \n",
    "\n",
    "In addition to businesses, a sentiment analysis model based on the SST-2 dataset can also benefit consumers by providing them with more personalized and relevant recommendations. For example, a movie streaming platform can use sentiment analysis to suggest movies to users based on their previous viewing history and the sentiment of the movies they have enjoyed in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9UBZzRuvUst"
   },
   "source": [
    "## Run at least three prediction models to try to predict the SST sentiment dataset well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLTIaMB3ChSW",
    "outputId": "3e3125cf-9831-48ec-ab47-e79cb468948e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: aimodelshare==0.0.189 in /usr/local/lib/python3.9/dist-packages (0.0.189)\n",
      "Requirement already satisfied: scipy==1.7.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.7.0)\n",
      "Requirement already satisfied: onnxmltools>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.11.2)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2.0.0+cu118)\n",
      "Requirement already satisfied: botocore==1.29.82 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.29.82)\n",
      "Requirement already satisfied: keras2onnx>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.7.0)\n",
      "Requirement already satisfied: PyJWT>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2.6.0)\n",
      "Requirement already satisfied: boto3==1.26.69 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.26.69)\n",
      "Requirement already satisfied: importlib-resources==5.10.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (5.10.0)\n",
      "Requirement already satisfied: docker==5.0.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (5.0.0)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (0.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.14.1)\n",
      "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.13.0)\n",
      "Requirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2.9.2)\n",
      "Requirement already satisfied: onnx==1.12.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.12.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2022.10.31)\n",
      "Requirement already satisfied: pydot==1.3.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (5.9.4)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn==1.2.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.2.1)\n",
      "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (3.19.6)\n",
      "Requirement already satisfied: Pympler==0.9 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (0.9)\n",
      "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (3.2)\n",
      "Requirement already satisfied: pathlib>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.0.1)\n",
      "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.14.0)\n",
      "Requirement already satisfied: shortuuid>=1.0.8 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.0.11)\n",
      "Requirement already satisfied: skl2onnx>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (0.40.0)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (1.16.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3==1.26.69->aimodelshare==0.0.189) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3==1.26.69->aimodelshare==0.0.189) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (1.26.15)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (2.27.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (1.5.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources==5.10.0->aimodelshare==0.0.189) (3.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot==1.3.0->aimodelshare==0.0.189) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (1.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.53.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (23.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.32.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (16.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (67.6.1)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.9/dist-packages (from keras2onnx>=1.7.0->aimodelshare==0.0.189) (0.5.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.7.0->aimodelshare==0.0.189) (15.0.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.11.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (3.7.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (1.5.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (2.0.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.11.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (16.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (8.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (4.39.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn>=0.11.2->aimodelshare==0.0.189) (2022.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2.0.12)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.4.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime>=1.7.0->aimodelshare==0.0.189) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->aimodelshare==0.0.189) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (6.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare==0.0.189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3PiJXBhC5y-",
    "outputId": "1326ab42-8ea6-4c0c-e926-6e0d48c6bfc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [=============================================>   ]\n",
      "\n",
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get competition data\n",
    "from aimodelshare import download_data\n",
    "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jT0qFCZFNzHq",
    "outputId": "fbdf319e-75d8-4042-b3c7-7ca7037202f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Rock is destined to be the 21st Century 's...\n",
       "1    The gorgeously elaborate continuation of `` Th...\n",
       "2    Singer/composer Bryan Adams contributes a slew...\n",
       "3                 Yet the act is still charming here .\n",
       "4    Whether or not you 're enlightened by any of D...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up X_train, X_test, and y_train_labels objects\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
    "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
    "\n",
    "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
    "\n",
    "# ohe encode Y data\n",
    "y_train = pd.get_dummies(y_train_labels)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzPoXPj3V7u"
   },
   "source": [
    "##2.   Preprocess data using keras tokenizer / Write and Save Preprocessor function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16QV9Y9TC3B3",
    "outputId": "45cec1c1-2c3d-4e26-a145-9bb583d3ea44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 40)\n",
      "(1821, 40)\n"
     ]
    }
   ],
   "source": [
    "# This preprocessor function makes use of the tf.keras tokenizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Build vocabulary from training text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# preprocessor tokenizes words and makes sure all documents have the same length\n",
    "def preprocessor(data, maxlen=40, max_words=10000):\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "    return X\n",
    "\n",
    "print(preprocessor(X_train).shape)\n",
    "print(preprocessor(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VGacc0LDaMA",
    "outputId": "7de7140f-7b68-4b52-9b05-ba04b0392907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your preprocessor is now saved to 'preprocessor.zip'\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.export_preprocessor(preprocessor,\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X52kECL43b-O"
   },
   "source": [
    "Model 1: Use an Embedding layer and Conv1d layers in at least one model\n",
    "\n",
    "\n",
    "\n",
    "**Model version 292**\n",
    "\n",
    "Accuracy: 80.68%\t\n",
    "f1-score: 80.56%\n",
    "\n",
    "I used a vocabulary of 10000 and embedding size 16 with one Conv1D layer of 32 units. This model performed very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCbBf8j9ClYl",
    "outputId": "76fef021-001d-406c-d69f-274d8d56433b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 36, 32)            2592      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,658\n",
      "Trainable params: 162,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.6643 - acc: 0.6145 - val_loss: 0.8428 - val_acc: 0.1488\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.6128 - acc: 0.6532 - val_loss: 0.7764 - val_acc: 0.3772\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.5002 - acc: 0.7670 - val_loss: 0.6431 - val_acc: 0.6199\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3736 - acc: 0.8481 - val_loss: 0.5656 - val_acc: 0.7081\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.2866 - acc: 0.8887 - val_loss: 0.5904 - val_acc: 0.6994\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.2290 - acc: 0.9113 - val_loss: 0.5411 - val_acc: 0.7522\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1861 - acc: 0.9306 - val_loss: 0.5795 - val_acc: 0.7457\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1518 - acc: 0.9454 - val_loss: 0.6155 - val_acc: 0.7464\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1251 - acc: 0.9568 - val_loss: 0.6014 - val_acc: 0.7608\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1021 - acc: 0.9664 - val_loss: 0.6947 - val_acc: 0.7370\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dense, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length=40))\n",
    "model.add(Conv1D(32, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pEhvnRiQDlY5"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtgkM02MDpkO",
    "outputId": "8d0a8f36-a2b3-42bc-bd46-34e2b8cbf70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set credentials using modelshare.org username/password\n",
    "\n",
    "from aimodelshare.aws import set_credentials\n",
    "    \n",
    "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
    "\n",
    "set_credentials(apiurl=apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "fKNGSww8EGgi"
   },
   "outputs": [],
   "source": [
    "#Instantiate Competition\n",
    "\n",
    "mycompetition= ai.Competition(apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ql4wksyEUnP",
    "outputId": "2e3635e6-774e-4b28-dc91-dc74fc0054b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 292\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 1: \n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNF385R9vZ4n"
   },
   "source": [
    "Model 2: Use an Embedding layer and LSTM layers in at least one model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Model version: 293**\n",
    "\n",
    "Accuracy: 59.17%\t\n",
    "f1-score: 52.78%\n",
    "\n",
    "I used an embedding size of 16 and vocabulary size of 10000. I used 64 LSTM units in the first layer and 32 in the next. Perhaps the model is too complex and may benefit from less LSTM units to produce better results. I will try this in my next set of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgSs5PAtPCZH",
    "outputId": "0a030a67-c24e-4edc-e1d4-d315ba2955ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 9s 29ms/step - loss: 0.6549 - acc: 0.6205 - val_loss: 0.8115 - val_acc: 0.3042\n"
     ]
    }
   ],
   "source": [
    "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 16, input_length=40))\n",
    "model2.add(LSTM(64, return_sequences=True, dropout=0.2))\n",
    "model2.add(LSTM(32, dropout=0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model2.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=1,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aIdmSpYVPYAw"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model2, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model2.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nszPPrfwPlUk",
    "outputId": "f406d3fe-7714-4e61-fb48-94ae82d47824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 9ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 293\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 2: \n",
    "\n",
    "#-- Generate predicted y values (Model 2)\n",
    "prediction_column_index=model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3Ecu35UPG13"
   },
   "source": [
    "Model 3: Use transfer learning with glove embeddings for at least one of these models\n",
    "\n",
    "**Model version: 306**\n",
    "\n",
    "Accuracy: 68.61%\t\n",
    "f1-score: 68.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucI8Dy531QYS",
    "outputId": "1a61abf0-fd98-4f88-d213-28504a473698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-17 20:29:41--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 20:29:41--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 20:29:41--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182753 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  3.21MB/s    in 3m 43s  \n",
      "\n",
      "2023-04-17 20:33:26 (3.69 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
    "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
    "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0KU029X6Nbl",
    "outputId": "641987ab-84b9-4bc6-a60b-6128ef6fce7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n",
      "  inflating: glove.6B.50d.txt        \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJkLWxii7R6Y",
    "outputId": "2041f9ab-c1d0-4318-ec5e-84f5b47995b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding data for 100 feature embedding matrix\n",
    "import os\n",
    "import numpy as np\n",
    "glove_dir = os.getcwd()\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "uXdoOiMt7VYR"
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "\n",
    "embedding_dim = 100 # change if you use txt files using larger number of features\n",
    "max_words = 10000 \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldjGLNEJ7XII",
    "outputId": "468652fa-5e41-4406-c4aa-ff6b2791ec4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 40, 100)           1000000   \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 4000)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                128032    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,128,098\n",
      "Trainable params: 1,128,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "\n",
    "\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.Embedding(10000, embedding_dim, input_length=40))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qErOa-657kTp",
    "outputId": "7abdb21b-e06a-42ab-98c0-16a24a29010e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.6291 - acc: 0.6463 - val_loss: 1.0346 - val_acc: 0.2991\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.4957 - acc: 0.7552 - val_loss: 0.7242 - val_acc: 0.6062\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.4048 - acc: 0.8165 - val_loss: 0.6113 - val_acc: 0.7103\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.3212 - acc: 0.8629 - val_loss: 0.7244 - val_acc: 0.6691\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2430 - acc: 0.9052 - val_loss: 1.0005 - val_acc: 0.5918\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.1788 - acc: 0.9371 - val_loss: 1.0783 - val_acc: 0.6055\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.1253 - acc: 0.9606 - val_loss: 1.2855 - val_acc: 0.5780\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0854 - acc: 0.9778 - val_loss: 1.1533 - val_acc: 0.6402\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.0557 - acc: 0.9890 - val_loss: 1.4652 - val_acc: 0.6243\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.0346 - acc: 0.9942 - val_loss: 1.5933 - val_acc: 0.6149\n"
     ]
    }
   ],
   "source": [
    "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
    "model3.layers[0].set_weights([embedding_matrix])\n",
    "model3.layers[0].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model3.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "model3.save_weights('pre_trained_glove_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRFbJ8pKNxCv",
    "outputId": "d554f775-1afc-4163-d783-2f4d3f7166cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 306\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model3, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model3.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "    #Submit Model 3: \n",
    "\n",
    "#-- Generate predicted y values (Model 3)\n",
    "prediction_column_index=model3.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 3 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model3.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP9kbC2IPW3e"
   },
   "source": [
    "Looking at all three models, the Conv1d model performed best by far. For the next part of this report, I will use advice from my teammates to improve my model.\n",
    "\n",
    "Namely I will, \n",
    "\n",
    "1.  Increase number of epochs for the Conv1d model\n",
    "2.  Decrease my first LSTM layer to 32 units\n",
    "3.  Add another dense layer to the transfer learning model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp4qvIfdQd02"
   },
   "source": [
    "Model 4: New Conv1d model\n",
    "\n",
    "**Model version 309**\n",
    "\n",
    "Accuracy: 79.80%\t\n",
    "f1-score: 79.69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GDY7_ovQgrA",
    "outputId": "556b7768-b8ef-4000-f57e-bfeb5e9398f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 36, 32)            2592      \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,658\n",
      "Trainable params: 162,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.6623 - acc: 0.6091 - val_loss: 0.9196 - val_acc: 0.1488\n",
      "Epoch 2/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.6029 - acc: 0.6635 - val_loss: 0.7593 - val_acc: 0.4220\n",
      "Epoch 3/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.4771 - acc: 0.7843 - val_loss: 0.6266 - val_acc: 0.6568\n",
      "Epoch 4/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.3595 - acc: 0.8551 - val_loss: 0.5620 - val_acc: 0.7247\n",
      "Epoch 5/15\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2816 - acc: 0.8887 - val_loss: 0.5270 - val_acc: 0.7579\n",
      "Epoch 6/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2274 - acc: 0.9128 - val_loss: 0.5796 - val_acc: 0.7457\n",
      "Epoch 7/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.1889 - acc: 0.9247 - val_loss: 0.5354 - val_acc: 0.7666\n",
      "Epoch 8/15\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.1589 - acc: 0.9377 - val_loss: 0.6764 - val_acc: 0.7197\n",
      "Epoch 9/15\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1321 - acc: 0.9505 - val_loss: 0.6799 - val_acc: 0.7355\n",
      "Epoch 10/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.1105 - acc: 0.9586 - val_loss: 0.6948 - val_acc: 0.7428\n",
      "Epoch 11/15\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0925 - acc: 0.9664 - val_loss: 0.6948 - val_acc: 0.7522\n",
      "Epoch 12/15\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0774 - acc: 0.9742 - val_loss: 0.7210 - val_acc: 0.7500\n",
      "Epoch 13/15\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0637 - acc: 0.9783 - val_loss: 0.7832 - val_acc: 0.7399\n",
      "Epoch 14/15\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.0528 - acc: 0.9832 - val_loss: 0.7905 - val_acc: 0.7449\n",
      "Epoch 15/15\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0437 - acc: 0.9877 - val_loss: 0.8956 - val_acc: 0.7319\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dense, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(10000, 16, input_length=40))\n",
    "model4.add(Conv1D(32, 5, activation='relu'))\n",
    "model4.add(GlobalMaxPooling1D())\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "model4.summary()\n",
    "\n",
    "model4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model4.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wc6gGNzKQqI0",
    "outputId": "8e7cf5aa-078c-4a59-d471-14fc49f4b734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 309\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model4, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model4.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "    #Submit Model 4: \n",
    "\n",
    "#-- Generate predicted y values (Model 4)\n",
    "prediction_column_index=model4.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 4 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model4.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldy_tDv1Q1Et"
   },
   "source": [
    "Model 5: New LSTM model\n",
    "\n",
    "**Model version 310**\n",
    "\n",
    "Accuracy: 79.39%\t\n",
    "f1-score: 80.78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkRj_tmlQ3cx",
    "outputId": "c2e52a25-a1e2-463c-ff48-6b3c0d790983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 9s 32ms/step - loss: 0.6502 - acc: 0.6212 - val_loss: 0.9195 - val_acc: 0.2428\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 4s 24ms/step - loss: 0.5023 - acc: 0.7599 - val_loss: 0.5607 - val_acc: 0.7681\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 5s 28ms/step - loss: 0.3896 - acc: 0.8300 - val_loss: 0.6429 - val_acc: 0.6864\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.3160 - acc: 0.8672 - val_loss: 0.5078 - val_acc: 0.7868\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.2696 - acc: 0.8898 - val_loss: 0.6125 - val_acc: 0.7146\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 5s 26ms/step - loss: 0.2329 - acc: 0.9064 - val_loss: 0.6410 - val_acc: 0.7218\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.2031 - acc: 0.9158 - val_loss: 0.7101 - val_acc: 0.7139\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 5s 29ms/step - loss: 0.1785 - acc: 0.9310 - val_loss: 0.7526 - val_acc: 0.7269\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.1621 - acc: 0.9353 - val_loss: 0.7517 - val_acc: 0.7514\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.1473 - acc: 0.9411 - val_loss: 0.7652 - val_acc: 0.7182\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(10000, 16, input_length=40))\n",
    "model5.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model5.add(LSTM(32, dropout=0.2))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model5.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4QdcGsZRH7x",
    "outputId": "2c79587c-639c-4932-ebe9-738f1af687b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 6ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 310\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model5, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model5.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "    #Submit Model 5: \n",
    "\n",
    "#-- Generate predicted y values (Model 5)\n",
    "prediction_column_index=model5.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 5 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model5.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kgt5QTR2RlQ1"
   },
   "source": [
    "Model 6: New transfer learning model\n",
    "\n",
    "**Model version: 311**\n",
    "\n",
    "Accuracy: 69.15%\t\n",
    "f1-score: 69.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzwaNKKsRpnV",
    "outputId": "8a00eb9e-5e12-4003-c1a7-9e8ac235a3e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, 40, 100)           1000000   \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4000)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                128032    \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,129,154\n",
      "Trainable params: 1,129,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = tf.keras.Sequential()\n",
    "model6.add(tf.keras.layers.Embedding(10000, embedding_dim, input_length=40))\n",
    "model6.add(tf.keras.layers.Flatten())\n",
    "model6.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model6.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model6.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPWufpkqRvuj",
    "outputId": "f8e462fe-3649-4653-e1fa-a15d3dd5099a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 2s 6ms/step - loss: 0.6279 - acc: 0.6422 - val_loss: 1.1176 - val_acc: 0.3194\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.5061 - acc: 0.7533 - val_loss: 0.6166 - val_acc: 0.6994\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.4074 - acc: 0.8065 - val_loss: 1.1463 - val_acc: 0.5130\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.3156 - acc: 0.8600 - val_loss: 1.4527 - val_acc: 0.4292\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.2339 - acc: 0.9030 - val_loss: 0.7275 - val_acc: 0.7254\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1601 - acc: 0.9391 - val_loss: 0.9594 - val_acc: 0.6879\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1061 - acc: 0.9637 - val_loss: 1.5905 - val_acc: 0.5874\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0718 - acc: 0.9758 - val_loss: 3.4050 - val_acc: 0.4783\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0451 - acc: 0.9854 - val_loss: 2.2126 - val_acc: 0.6040\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.0271 - acc: 0.9928 - val_loss: 1.8749 - val_acc: 0.6777\n"
     ]
    }
   ],
   "source": [
    "model6.layers[0].set_weights([embedding_matrix])\n",
    "model6.layers[0].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model6.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model6.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "model6.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBMbi09VRxe4",
    "outputId": "eb92dffe-f71c-4822-a632-f2d2694ba576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 311\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model6, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model6.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "    #Submit Model 6: \n",
    "\n",
    "#-- Generate predicted y values (Model 6)\n",
    "prediction_column_index=model6.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 5 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model6.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6vyMh6WTMzc"
   },
   "source": [
    "Overall, the hyperparameter changes I derived from my groupmates did help model improvement to some extent.\n",
    "\n",
    "For the Conv1D model, increasing epochs actually slightly decreased accuracy and f1-score. This could be due to overfitting. Eitherways, the Conv1D model on a whole was already my best performing one.\n",
    "\n",
    "For the other two models, the modifications improved the model performance. However, these still did not perform as well as the Conv1D model.\n",
    "\n",
    "Hence, I would conclude that some important hyperparameters would be using a Conv1D(32, 5, activation='relu') layer and trained using 10 epochs and batch size of 32."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
